#
# =======================================
# AUTHOR        : Claudio Prato @ Team EA
# CREATE DATE   : 2022/06/09
# PURPOSE       : Setup the RedHat Cluster Logging Operator
# SPECIAL NOTES :
# =======================================
#
apiVersion: template.openshift.io/v1
kind: Template
labels:
  template: dedalus-cluster-logging-template
metadata:
  annotations:
    description: |-
      Cluster Logging Operator definition with persistent storage.
      For more information about using this template, including OpenShift considerations, see https://github.com/dedalus-enterprise-architect/efk-resources/blob/main/README.md.
    iconClass: icon-d4center
    tags: dedalus-cluster-logging,dedalus
  name: dedalus-cluster-logging
objects:
# :::
# ::: Create the Namespace: openshift-logging
# :::
- apiVersion: v1
  kind: Namespace
  metadata:
    name: openshift-logging
    annotations:
      openshift.io/node-selector: ""
    labels:
      openshift.io/cluster-monitoring: "true"
# :::
# ::: Cluster Logging: OperatorGroup
# :::
- apiVersion: operators.coreos.com/v1
  kind: OperatorGroup
  metadata:
    name: cluster-logging
    namespace: openshift-logging
    labels:
      app: cl-logging-dedalus
  spec:
    targetNamespaces:
    - openshift-logging
# :::
# ::: Cluster Logging: Operator Subscription
# :::
- apiVersion: operators.coreos.com/v1alpha1
  kind: Subscription
  metadata:
    annotations:
      template.alpha.openshift.io/wait-for-ready: "true"
    name: cluster-logging
    # For AllNamespaces install mode usage, specify the 'openshift-operators' namespace.
    # Otherwise, specify the relevant single namespace for SingleNamespace install mode usage.
    # look for installModes by command: 'oc get packagemanifests cluster-logging -o yaml'
    namespace: openshift-logging
    labels:
      operators.coreos.com/cluster-logging.openshift-logging: ''
      app: cl-logging-dedalus
  spec:
    # Name of the channel to subscribe to.
    # look for the channel version available by command: 'oc get packagemanifests cluster-logging -o yaml'
    channel: 'stable'
    # Set the approval strategy to Manual in case your specified version is superseded by a later version in the catalog.
    # This plan prevents an automatic upgrade to a later version and requires manual approval before the starting CSV can complete the installation.
    installPlanApproval: Automatic
    # Name of the Operator to subscribe to
    name: cluster-logging
    # Name of the catalog source that provides the Operator.
    # you can choose among 'redhat-operators' and 'community-operators'
    # source: cluster-logging-catalog
    source: redhat-operators
    # Namespace of the catalog source. Use openshift-marketplace for the default OperatorHub catalog sources.
    sourceNamespace: openshift-marketplace
    # Set a specific version of an Operator CSV
    startingCSV: cluster-logging.5.4.1-24
# :::
# ::: Cluster Logging: Cluster Logging Instance with persistent storage
# :::
- apiVersion: logging.openshift.io/v1
  kind: ClusterLogging
  metadata:
    name: instance
    namespace: openshift-logging
    # annotations:
    #   template.alpha.openshift.io/wait-for-ready: "true"
    labels:
      app: cl-logging-dedalus
  spec:
    collection:
      logs:
        type: fluentd
        fluentd: {}
    logStore:
      elasticsearch:
        nodeCount: 1
        proxy:
          resources:
            limits:
              memory: 256Mi
            requests:
              memory: 256Mi
        # Specify a redundancy policy for the shards. The change is applied upon saving the changes.
        #  - FullRedundancy: Elasticsearch fully replicates the primary shards for each index to every data node. This provides the highest safety, but at the cost of the highest amount of disk required and the poorest performance.
        #  - MultipleRedundancy: Elasticsearch fully replicates the primary shards for each index to half of the data nodes. This provides a good tradeoff between safety and performance.
        #  - SingleRedundancy: Elasticsearch makes one copy of the primary shards for each index. Logs are always available and recoverable as long as at least two data nodes exist. Better performance than MultipleRedundancy, when using 5 or more nodes. You cannot apply this policy on deployments of single Elasticsearch node.
        #  - ZeroRedundancy: Elasticsearch does not make copies of the primary shards. Logs might be unavailable or lost in the event a node is down or fails. Use this mode when you are more concerned with performance than safety, or have implemented your own disk/PVC backup/restore strategy.
        redundancyPolicy: ZeroRedundancy
        resources:
          limits:
            memory: 4Gi
          requests:
            memory: 4Gi
        storage:
          size: 50G
          storageClassName: "${STORAGECLASS}"
      retentionPolicy:
        application:
          maxAge: 7d
        audit:
          maxAge: 2d
        infra:
          maxAge: 2d
      type: elasticsearch
    managementState: Managed
    visualization:
      kibana:
        replicas: 1
      type: kibana
# :::
# ::: Cluster Logging: ClusterLogForwarder Instance
# :::
- apiVersion: logging.openshift.io/v1
  kind: ClusterLogForwarder
  metadata:
    name: instance
    namespace: openshift-logging
    # annotations:
    #   template.alpha.openshift.io/wait-for-ready: "true"
    labels:
      app: cl-logging-dedalus
  spec:
    outputDefaults:
      elasticsearch:
        structuredTypeKey: kubernetes.namespace_name
        structuredTypeName: nologformat
    pipelines:
      - inputRefs:
          - application
        name: application-json
        outputRefs:
          - default
        parse: json
      - inputRefs:
          - infrastructure
          - audit
        name: default-logging
        outputRefs:
          - default
parameters:
- name: STORAGECLASS
  displayName: Storage Class
  description: Type the Storage Class available on the cluster
  required: false
  value: 